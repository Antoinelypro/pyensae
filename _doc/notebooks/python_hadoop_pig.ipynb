{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Hadoop Pig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims at showing how to submit a PIG job to remote hadoop cluster (tested with Cloudera). It works better if you know Hadoop otherwise I recommend reading [Map/Reduce avec PIG](http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx2/notebooks/td3a_cenonce_session6.html#td3acenoncesession6rst) (French). First, we download data. We are going to upload that data to the remote cluster. The Hadoop distribution tested here is [Cloudera](http://www.cloudera.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    downloading of  https://archive.ics.uci.edu/ml/machine-learning-databases/00196/ConfLongDemo_JSI.txt  to  ConfLongDemo_JSI.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ConfLongDemo_JSI.txt'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyensae\n",
    "pyensae.download_data(\"ConfLongDemo_JSI.txt\", website=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00196/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We open a SSH connection to the bridge which can communicate to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"background-color:gainsboro; padding:2px; border:0px;\"><b>credentials</b>\n",
       "<br />password <input type=\"password\" id=\"ssh_remote_hadooppassword\" value=\"\" size=\"80\" />\n",
       "<br />server <input type=\"text\" id=\"ssh_remote_hadoopserver\" value=\"\" size=\"80\" />\n",
       "<br />username <input type=\"text\" id=\"ssh_remote_hadoopusername\" value=\"\" size=\"80\" />\n",
       "<br /><button onclick=\"set_valuessh_remote_hadoop()\">Ok</button></div>\n",
       "<script type=\"text/Javascript\">\n",
       "function set_valuessh_remote_hadoop(){\n",
       "   command='ssh_remote_hadoop = {' ;\n",
       "   var ssh_remote_hadooppasswordvar_value = document.getElementById('ssh_remote_hadooppassword').value;\n",
       "   command += '\"password\":\"' + ssh_remote_hadooppasswordvar_value + '\",';\n",
       "   var ssh_remote_hadoopservervar_value = document.getElementById('ssh_remote_hadoopserver').value;\n",
       "   command += '\"server\":\"' + ssh_remote_hadoopservervar_value + '\",';\n",
       "   var ssh_remote_hadoopusernamevar_value = document.getElementById('ssh_remote_hadoopusername').value;\n",
       "   command += '\"username\":\"' + ssh_remote_hadoopusernamevar_value + '\",';\n",
       "   command += '}';\n",
       "   var kernel = IPython.notebook.kernel;\n",
       "   kernel.execute(command);\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0x742c9f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyquickhelper\n",
    "params={\"server\":\"\", \"username\":\"\", \"password\":\"\"}\n",
    "pyquickhelper.open_html_form(params=params,title=\"credentials\",key_save=\"ssh_remote_hadoop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "password = ssh_remote_hadoop[\"password\"]\n",
    "server = ssh_remote_hadoop[\"server\"]\n",
    "username = ssh_remote_hadoop[\"username\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We open the SSH connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyensae.remote.remote_connection.ASSHClient at 0xa9b16f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%remote_open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check  the content of the remote machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "total 36\n",
       "drwxrwxr-x 2 xavierdupre xavierdupre 4096 Oct 23 02:55 ConfLongDemo_JSI.small.example.walking2.txt\n",
       "-rw-rw-r-- 1 xavierdupre xavierdupre    0 Oct 23 02:29 dummy\n",
       "-rw-rw-r-- 1 xavierdupre xavierdupre  631 Oct 23 02:49 essai.pig\n",
       "-rw-rw-r-- 1 xavierdupre xavierdupre  242 Oct 22 00:51 ex.py\n",
       "-rw-rw-r-- 1 xavierdupre xavierdupre  317 Oct 23 02:39 select2f.pig\n",
       "-rw-rw-r-- 1 xavierdupre xavierdupre  337 Oct 23 02:58 select2.pig\n",
       "-rw-rw-r-- 1 xavierdupre xavierdupre  344 Oct 23 03:12 select_nowait.pig\n",
       "-rw-rw-r-- 1 xavierdupre xavierdupre 8230 Oct 23 03:13 select_nowait.redirect.err\n",
       "-rw-rw-r-- 1 xavierdupre xavierdupre    0 Oct 23 03:12 select_nowait.redirect.out\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0xb68a8b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%remote_cmd ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the content on the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "Found 10 items\n",
       "drwx------   - xavierdupre xavierdupre          0 2014-10-23 03:13 .staging\n",
       "-rw-r--r--   3 xavierdupre xavierdupre     132727 2014-10-22 02:03 ConfLongDemo_JSI.small.example.txt\n",
       "drwxr-xr-x   - xavierdupre xavierdupre          0 2014-10-23 02:18 ConfLongDemo_JSI.small.example.walking.txt\n",
       "drwxr-xr-x   - xavierdupre xavierdupre          0 2014-10-23 02:54 ConfLongDemo_JSI.small.example.walking2.txt\n",
       "drwxr-xr-x   - xavierdupre xavierdupre          0 2014-10-23 03:13 ConfLongDemo_JSI.small.example2.walking.nowait.txt\n",
       "drwxr-xr-x   - xavierdupre xavierdupre          0 2014-10-23 02:59 ConfLongDemo_JSI.small.example2.walking.txt\n",
       "drwxr-xr-x   - xavierdupre xavierdupre          0 2014-10-23 02:18 oozie-oozi\n",
       "-rw-r--r--   3 xavierdupre xavierdupre        324 2014-10-23 02:24 select2.pig\n",
       "drwxr-xr-x   - xavierdupre xavierdupre          0 2014-08-29 00:19 stations_count_2013-05-24.paris.short.pig.2.txt\n",
       "drwxr-xr-x   - xavierdupre xavierdupre          0 2014-10-23 02:50 test\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0x7bb37d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%remote_cmd hdfs dfs -ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We upload the file on the bridge (we should zip it first, it would reduce the uploading time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%remote_up ConfLongDemo_JSI.txt ConfLongDemo_JSI.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check it got there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "ConfLongDemo_JSI.txt\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0xb693750>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%remote_cmd ls Conf*JSI.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put it on the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0xbb7a110>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%remote_cmd hdfs dfs -put ConfLongDemo_JSI.txt ConfLongDemo_JSI.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check it was put on the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "Found 1 items\n",
       "-rw-r--r--   3 xavierdupre xavierdupre   21546346 2014-10-23 22:33 ConfLongDemo_JSI.txt\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0xbb7a890>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%remote_cmd hdfs dfs -ls Conf*JSI.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a simple PIG program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%PIG filter_example.pig\n",
    "\n",
    "myinput = LOAD 'ConfLongDemo_JSI.txt' USING PigStorage(',') AS\n",
    "    (index:long, sequence, tag, timestamp:long, dateformat, x:double,y:double, z:double, activity) ;\n",
    "filt = FILTER myinput BY activity == 'walking' ;\n",
    "STORE filt INTO 'ConfLongDemo_JSI.walking.txt' USING PigStorage() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0xbb7a930>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%jobsubmit filter_example.pig filter_example.redirect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the redirected files were created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "filter_example.redirect.err\n",
       "filter_example.redirect.out\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0xbb7a790>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%remote_cmd ls f*redirect*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the tail on a regular basis to see the job running (some other commands can be used to monitor jobs, ``%remote_cmd mapred --help``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "Total bags proactively spilled: 0\n",
       "Total records proactively spilled: 0\n",
       "\n",
       "Job DAG:\n",
       "job_1410345524631_0010\n",
       "\n",
       "\n",
       "2014-10-23 22:35:49,088 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
       "2014-10-23 22:35:49,241 [main] WARN  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Encountered Warning ACCESSING_NON_EXISTENT_FIELD 164860 time(s).\n",
       "2014-10-23 22:35:49,241 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0xbb7ac50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%remote_cmd tail filter_example.redirect.err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "Found 2 items\n",
       "-rw-r--r--   3 xavierdupre xavierdupre          0 2014-10-23 22:35 ConfLongDemo_JSI.walking.txt/_SUCCESS\n",
       "-rw-r--r--   3 xavierdupre xavierdupre          0 2014-10-23 22:35 ConfLongDemo_JSI.walking.txt/part-m-00000\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0xbb7afd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%remote_cmd hdfs dfs -ls Conf*JSI.walking.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, the stream has to downloaded to the bridge and then to the local machine with ``%remote_down``. We finally close the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%remote_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**END**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}